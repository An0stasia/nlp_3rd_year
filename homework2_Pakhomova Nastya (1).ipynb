{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c1a0e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting stanza\n",
      "  Obtaining dependency information for stanza from https://files.pythonhosted.org/packages/88/4f/064015f46172c860b02148db65acd67e4925900b426f66cd0f5729d1c0d1/stanza-1.6.1-py3-none-any.whl.metadata\n",
      "  Downloading stanza-1.6.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting emoji (from stanza)\n",
      "  Obtaining dependency information for emoji from https://files.pythonhosted.org/packages/96/c6/0114b2040a96561fd1b44c75df749bbd3c898bf8047fb5ce8d7590d2dee6/emoji-2.8.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading emoji-2.8.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from stanza) (1.24.2)\n",
      "Collecting protobuf>=3.15.0 (from stanza)\n",
      "  Obtaining dependency information for protobuf>=3.15.0 from https://files.pythonhosted.org/packages/88/12/efb5896c901382548ecb58d0449885a8f9aa62bb559d65e5a8a47f122629/protobuf-4.24.4-cp37-abi3-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading protobuf-4.24.4-cp37-abi3-macosx_10_9_universal2.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from stanza) (2.28.2)\n",
      "Collecting torch>=1.3.0 (from stanza)\n",
      "  Obtaining dependency information for torch>=1.3.0 from https://files.pythonhosted.org/packages/7b/7c/4d8728e6f8dbe2b8af054bd92c290d94c633270443514e3ee4b768125cf9/torch-2.1.0-cp311-none-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading torch-2.1.0-cp311-none-macosx_11_0_arm64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from stanza) (4.64.1)\n",
      "Collecting filelock (from torch>=1.3.0->stanza)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/5e/5d/97afbafd9d584ff1b45fcb354a479a3609bd97f912f8f1f6c563cb1fae21/filelock-3.12.4-py3-none-any.whl.metadata\n",
      "  Downloading filelock-3.12.4-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (4.4.0)\n",
      "Collecting sympy (from torch>=1.3.0->stanza)\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx (from torch>=1.3.0->stanza)\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (3.1.2)\n",
      "Collecting fsspec (from torch>=1.3.0->stanza)\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/fe/d3/e1aa96437d944fbb9cc95d0316e25583886e9cd9e6adc07baad943524eda/fsspec-2023.9.2-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2023.9.2-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->stanza) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->stanza) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->stanza) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->stanza) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch>=1.3.0->stanza) (2.1.1)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.3.0->stanza)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading stanza-1.6.1-py3-none-any.whl (881 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.2/881.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.24.4-cp37-abi3-macosx_10_9_universal2.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.4/409.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.0-cp311-none-macosx_11_0_arm64.whl (59.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading emoji-2.8.0-py2.py3-none-any.whl (358 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.12.4-py3-none-any.whl (11 kB)\n",
      "Downloading fsspec-2023.9.2-py3-none-any.whl (173 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: mpmath, sympy, protobuf, networkx, fsspec, filelock, emoji, torch, stanza\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed emoji-2.8.0 filelock-3.12.4 fsspec-2023.9.2 mpmath-1.3.0 networkx-3.1 protobuf-4.24.4 stanza-1.6.1 sympy-1.12 torch-2.1.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "119b8745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting spacy==3.7.0\n",
      "  Obtaining dependency information for spacy==3.7.0 from https://files.pythonhosted.org/packages/7b/f2/a919c2a5c0f0250070cc8f7336b814e5d356d90247c2507462b3baefcdf9/spacy-3.7.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading spacy-3.7.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy==3.7.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy==3.7.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy==3.7.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy==3.7.0) (3.0.8)\n",
      "Collecting thinc<8.3.0,>=8.1.8 (from spacy==3.7.0)\n",
      "  Obtaining dependency information for thinc<8.3.0,>=8.1.8 from https://files.pythonhosted.org/packages/97/d6/0321fa57b30bde80e2297e5835915f56edef58b6e6a970f8c09a30b446aa/thinc-8.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached thinc-8.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy==3.7.0) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy==3.7.0) (2.4.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy==3.7.0) (0.3.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy==3.7.0) (0.4.2)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy==3.7.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy==3.7.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy==3.7.0) (4.64.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy==3.7.0) (2.28.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy==3.7.0) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy==3.7.0) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy==3.7.0) (22.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy==3.7.0) (1.24.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.0) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.0) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy==3.7.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy==3.7.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy==3.7.0) (8.1.3)\n",
      "Requirement already satisfied: cloudpathlib<0.16.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy==3.7.0) (0.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->spacy==3.7.0) (2.1.1)\n",
      "Downloading spacy-3.7.0-cp311-cp311-macosx_11_0_arm64.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached thinc-8.2.1-cp311-cp311-macosx_11_0_arm64.whl (777 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: thinc, spacy\n",
      "  Attempting uninstall: thinc\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: thinc 8.0.17\n",
      "    Uninstalling thinc-8.0.17:\n",
      "      Successfully uninstalled thinc-8.0.17\n",
      "  Attempting uninstall: spacy\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: spacy 3.1.7\n",
      "    Uninstalling spacy-3.1.7:\n",
      "      Successfully uninstalled spacy-3.1.7\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "en-core-web-lg 3.5.0 requires spacy<3.6.0,>=3.5.0, but you have spacy 3.7.0 which is incompatible.\n",
      "en-core-web-sm 3.5.0 requires spacy<3.6.0,>=3.5.0, but you have spacy 3.7.0 which is incompatible.\n",
      "ru-core-news-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed spacy-3.7.0 thinc-8.2.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.7.0/ru_core_news_sm-3.7.0.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.7.0/ru_core_news_sm-3.7.0.tar.gz (15.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ru-core-news-sm==3.7.0) (3.7.0)\n",
      "Requirement already satisfied: pymorphy3>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ru-core-news-sm==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0) (0.6.2)\n",
      "Requirement already satisfied: pymorphy3-dicts-ru in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0) (2.4.417150.4580142)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.4.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.3.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.4.2)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (4.64.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.28.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (22.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.24.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (8.1.3)\n",
      "Requirement already satisfied: cloudpathlib<0.16.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.1.1)\n",
      "Building wheels for collected packages: ru-core-news-sm\n",
      "  Building wheel for ru-core-news-sm (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ru-core-news-sm: filename=ru_core_news_sm-3.7.0-py3-none-any.whl size=15257474 sha256=10a6707c666a90146da8818256803f77bd43f3552ef02498e356c567b4c4480f\n",
      "  Stored in directory: /Users/nastyapakhomova/Library/Caches/pip/wheels/b9/33/ef/5ab8e33fbc8c633dc7203d2f5be79e675f18fe127abaa1610b\n",
      "Successfully built ru-core-news-sm\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: ru-core-news-sm\n",
      "  Attempting uninstall: ru-core-news-sm\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: ru-core-news-sm 3.1.0\n",
      "    Uninstalling ru-core-news-sm-3.1.0:\n",
      "      Successfully uninstalled ru-core-news-sm-3.1.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed ru-core-news-sm-3.7.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy==3.7.0\n",
    "%pip install https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.7.0/ru_core_news_sm-3.7.0.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c78858a",
   "metadata": {},
   "source": [
    "Я решила выбрать этот текст, потому что есть неоднозначные моменты в корпусе: омонимия (\"пропасть\" как существительное, наречие, междометие и глагол); сложные слова (\"миллионометр\", \"полуколебаний\", \"Москомэкспертиза\", \"восьмидесятиэтажного\"); несуществующие формы (\"стригя\", \"побежу\", \"нельзей\", \"висю\", \"деревяннее\"); аббревиатуры (\"МФТИ\", \"ОГПУ\") и топоним (\"Лхаса\"); а авторские слова (\"варкалось\", \"исполин\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de06f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Перед нами была огромная пропасть.\n",
    "      Грибов здесь можно набрать пропасть.\n",
    "      Тьфу ты, пропасть, как надоел!\n",
    "      В таком месте легко пропасть.\n",
    "\n",
    "      Антуан ЛеКультр сумел поднять точность обработки деталей механизма до невиданного прежде уровня благодаря изобретению миллионометра — прибора для измерения с точностью до микрона.\n",
    "\n",
    "      Частота колебаний баланса определяется числом полуколебаний балансового колеса в час.\n",
    "\n",
    "      Москомэкспертиза согласовала проект строительства восьмидесятиэтажного многофункционального комплекса.\n",
    "\n",
    "      Постоянно стригя волосы, мы заставляем организм все время вкладывать огромные ресурсы в их рост.\n",
    "\n",
    "      Этим скипетром я побежу даже лорда демонов.\n",
    "\n",
    "      За то нельзя браться, а за это еще нельзей!\n",
    "\n",
    "      Я висю под потолком вместо лампы.\n",
    "\n",
    "      Нижняя полка деревяннее верхней.\n",
    "\n",
    "      Среди сотрудников и выпускников МФТИ 10 нобелевских лауреатов.\n",
    "\n",
    "      ОГПУ направило в Лхасу свою новую экспедицию.\n",
    "\n",
    "      Джоулево тепло, выделявшееся в образце, не могло приводить к перегреву.\n",
    "\n",
    "      Сяпала Калуша с калушатами по напушке. И увазила бутявку, и волит:\n",
    "      — Калушата! Калушаточки! Бутявка.\n",
    "      Калушата присяпали и бутявку стрямкали. И подудонились.\n",
    "      А Калуша волит:\n",
    "      — Оее! Бутявка некузявая!\n",
    "      Калушата бутявку вычучили.\n",
    "      Бутявка вздребезнулась, сопритюкнулась и усяпала с напушки.\n",
    "      А Калуша волит:\n",
    "      — Калушаточки, бутявок не трямкают, бутявки дюбые и зюмо некузявые. От бутявок дудонятся.\n",
    "      А бутявка волит за напушкой:\n",
    "      — Калушата подудонились! Зюмо некузявые! Пуськи бятые!\n",
    "\n",
    "      Варкалось. Хливкие шорьки\n",
    "      Пырялись по наве,\n",
    "      И хрюкотали зелюки,\n",
    "      Как мюмзики в мове.\n",
    "\n",
    "      О бойся Бармаглота, сын!\n",
    "      Он так свирлеп и дик,\n",
    "      А в глyще рымит исполин -\n",
    "      Злопастный Брандашмыг.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0192ab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ru_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0848a907",
   "metadata": {},
   "source": [
    "Размечаем части речи у каждого слова, делая свой \"золотой стандарт\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0816ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "golden_standard = \"\"\"Перед ADP\n",
    "нами PRON\n",
    "была VERB\n",
    "огромная ADJ\n",
    "пропасть NOUN\n",
    "Грибов NOUN\n",
    "здесь ADV\n",
    "можно ADV\n",
    "набрать VERB\n",
    "пропасть ADV\n",
    "Тьфу INTJ\n",
    "ты PRON\n",
    "пропасть INTJ\n",
    "как CONJ\n",
    "надоел VERB\n",
    "В ADP\n",
    "таком DET\n",
    "месте NOUN\n",
    "легко ADJ\n",
    "пропасть VERB\n",
    "Антуан NOUN\n",
    "ЛеКультр NOUN\n",
    "сумел VERB\n",
    "поднять VERB\n",
    "точность NOUN\n",
    "обработки NOUN\n",
    "деталей NOUN\n",
    "механизма NOUN\n",
    "до ADP\n",
    "невиданного ADJ\n",
    "прежде ADV\n",
    "уровня NOUN\n",
    "благодаря ADP\n",
    "изобретению NOUN\n",
    "миллионометра NOUN\n",
    "прибора NOUN\n",
    "для ADP\n",
    "измерения NOUN\n",
    "с ADP\n",
    "точностью NOUN\n",
    "до ADP\n",
    "микрона NOUN\n",
    "Частота NOUN\n",
    "колебаний NOUN\n",
    "баланса NOUN\n",
    "определяется VERB\n",
    "числом NOUN\n",
    "полуколебаний NOUN\n",
    "балансового ADJ\n",
    "колеса NOUN\n",
    "в ADP\n",
    "час NOUN\n",
    "Москомэкспертиза NOUN\n",
    "согласовала VERB\n",
    "проект NOUN\n",
    "строительства NOUN\n",
    "восьмидесятиэтажного ADJ\n",
    "многофункционального ADJ\n",
    "комплекса NOUN\n",
    "Постоянно ADV\n",
    "стригя VERB\n",
    "волосы NOUN\n",
    "мы PRON\n",
    "заставляем VERB\n",
    "организм NOUN\n",
    "все DET\n",
    "время NOUN\n",
    "вкладывать VERB\n",
    "огромные ADJ\n",
    "ресурсы NOUN\n",
    "в ADP\n",
    "их DET\n",
    "рост NOUN\n",
    "Этим DET\n",
    "скипетром NOUN\n",
    "я PRON\n",
    "побежу VERB\n",
    "даже PART\n",
    "лорда NOUN\n",
    "демонов NOUN\n",
    "За ADP\n",
    "то PRON\n",
    "нельзя ADV\n",
    "браться VERB\n",
    "а CONJ\n",
    "за ADP\n",
    "это PRON\n",
    "еще ADV\n",
    "нельзей ADV\n",
    "Я PRON\n",
    "висю VERB\n",
    "под ADP\n",
    "потолком NOUN\n",
    "вместо ADP\n",
    "лампы NOUN\n",
    "Нижняя ADJ\n",
    "полка NOUN\n",
    "деревяннее ADJ\n",
    "верхней ADJ\n",
    "Среди ADP\n",
    "сотрудников NOUN\n",
    "и CONJ\n",
    "выпускников NOUN\n",
    "МФТИ NOUN\n",
    "нобелевских ADJ\n",
    "лауреатов NOUN\n",
    "ОГПУ NOUN\n",
    "направило VERB\n",
    "в ADP\n",
    "Лхасу NOUN\n",
    "свою DET\n",
    "новую ADJ\n",
    "экспедицию NOUN\n",
    "Джоулево ADJ\n",
    "тепло NOUN\n",
    "выделявшееся VERB\n",
    "в ADP\n",
    "образце NOUN\n",
    "не PART\n",
    "могло VERB\n",
    "приводить VERB\n",
    "к ADP\n",
    "перегреву NOUN\n",
    "Сяпала VERB\n",
    "Калуша NOUN\n",
    "с ADP\n",
    "калушатами NOUN\n",
    "по ADP\n",
    "напушке NOUN\n",
    "И CONJ\n",
    "увазила VERB\n",
    "бутявку NOUN\n",
    "и CONJ\n",
    "волит VERB\n",
    "Калушата NOUN\n",
    "Калушаточки NOUN\n",
    "Бутявка NOUN\n",
    "Калушата NOUN\n",
    "присяпали VERB\n",
    "и CONJ\n",
    "бутявку NOUN\n",
    "стрямкали VERB\n",
    "И CONJ\n",
    "подудонились VERB\n",
    "А CONJ\n",
    "Калуша NOUN\n",
    "волит VERB\n",
    "Оее INTJ\n",
    "Бутявка NOUN\n",
    "некузявая ADJ\n",
    "Калушата NOUN\n",
    "бутявку NOUN\n",
    "вычучили VERB\n",
    "Бутявка NOUN\n",
    "вздребезнулась VERB\n",
    "сопритюкнулась VERB\n",
    "и CONJ\n",
    "усяпала VERB\n",
    "с ADP\n",
    "напушки NOUN\n",
    "А CONJ\n",
    "Калуша NOUN\n",
    "волит VERB\n",
    "Калушаточки NOUN\n",
    "бутявок NOUN\n",
    "не PART\n",
    "трямкают VERB\n",
    "бутявки NOUN\n",
    "дюбые ADJ\n",
    "и CONJ\n",
    "зюмо ADV\n",
    "некузявые ADJ\n",
    "От ADP\n",
    "бутявок NOUN\n",
    "дудонятся VERB\n",
    "А CONJ\n",
    "бутявка NOUN\n",
    "волит VERB\n",
    "за ADP\n",
    "напушкой NOUN\n",
    "Калушата NOUN\n",
    "подудонились VERB\n",
    "Зюмо ADV\n",
    "некузявые ADJ\n",
    "Пуськи NOUN\n",
    "бятые ADJ\n",
    "Варкалось VERB\n",
    "Хливкие ADJ\n",
    "шорьки NOUN\n",
    "Пырялись VERB\n",
    "по ADP\n",
    "наве NOUN\n",
    "И CONJ\n",
    "хрюкотали VERB\n",
    "зелюки NOUN\n",
    "Как CONJ\n",
    "мюмзики NOUN\n",
    "в ADP\n",
    "мове NOUN\n",
    "О INTJ\n",
    "бойся VERB\n",
    "Бармаглота NOUN\n",
    "сын NOUN\n",
    "Он PRON\n",
    "так ADV\n",
    "свирлеп ADJ\n",
    "и CONJ\n",
    "дик ADJ\n",
    "А CONJ\n",
    "в ADP\n",
    "глyще NOUN\n",
    "рымит VERB\n",
    "исполин NOUN\n",
    "Злопастный ADJ\n",
    "Брандашмыг NOUN\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240b2c8e",
   "metadata": {},
   "source": [
    "Разделяем наш золотой стандарт на слова и тэги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7231bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "tags = []\n",
    "sents = golden_standard.split('\\n')\n",
    "for sent in sents:\n",
    "    parsed = sent.split(' ')\n",
    "    words.append(parsed[0])\n",
    "    tags.append(parsed[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7a1d11",
   "metadata": {},
   "source": [
    "1. Ипользуем первый тэггер spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d0b0870f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Перед ADP\n",
      "нами PRON\n",
      "была VERB\n",
      "огромная ADJ\n",
      "пропасть NOUN\n",
      "Грибов PROPN\n",
      "здесь ADV\n",
      "можно ADV\n",
      "набрать VERB\n",
      "пропасть NOUN\n",
      "Тьфу ADV\n",
      "ты PRON\n",
      "пропасть NOUN\n",
      "как SCONJ\n",
      "надоел VERB\n",
      "В ADP\n",
      "таком DET\n",
      "месте NOUN\n",
      "легко ADV\n",
      "пропасть NOUN\n",
      "Антуан PROPN\n",
      "ЛеКультр PROPN\n",
      "сумел VERB\n",
      "поднять VERB\n",
      "точность NOUN\n",
      "обработки NOUN\n",
      "деталей NOUN\n",
      "механизма NOUN\n",
      "до ADP\n",
      "невиданного ADJ\n",
      "прежде ADV\n",
      "уровня NOUN\n",
      "благодаря ADP\n",
      "изобретению NOUN\n",
      "миллионометра NOUN\n",
      "прибора NOUN\n",
      "для ADP\n",
      "измерения NOUN\n",
      "с ADP\n",
      "точностью NOUN\n",
      "до ADP\n",
      "микрона NOUN\n",
      "Частота NOUN\n",
      "колебаний NOUN\n",
      "баланса NOUN\n",
      "определяется VERB\n",
      "числом NOUN\n",
      "полуколебаний NOUN\n",
      "балансового ADJ\n",
      "колеса NOUN\n",
      "в ADP\n",
      "час NOUN\n",
      "Москомэкспертиза PROPN\n",
      "согласовала VERB\n",
      "проект NOUN\n",
      "строительства NOUN\n",
      "восьмидесятиэтажного ADJ\n",
      "многофункционального ADJ\n",
      "комплекса NOUN\n",
      "Постоянно ADV\n",
      "стригя VERB\n",
      "волосы NOUN\n",
      "мы PRON\n",
      "заставляем VERB\n",
      "организм NOUN\n",
      "все DET\n",
      "время NOUN\n",
      "вкладывать VERB\n",
      "огромные ADJ\n",
      "ресурсы NOUN\n",
      "в ADP\n",
      "их DET\n",
      "рост NOUN\n",
      "Этим DET\n",
      "скипетром NOUN\n",
      "я PRON\n",
      "побежу VERB\n",
      "даже PART\n",
      "лорда NOUN\n",
      "демонов NOUN\n",
      "За ADP\n",
      "то PRON\n",
      "нельзя ADV\n",
      "браться VERB\n",
      "а CCONJ\n",
      "за ADP\n",
      "это PRON\n",
      "еще ADV\n",
      "нельзей NOUN\n",
      "Я PRON\n",
      "висю ADV\n",
      "под ADP\n",
      "потолком NOUN\n",
      "вместо ADP\n",
      "лампы NOUN\n",
      "Нижняя ADJ\n",
      "полка NOUN\n",
      "деревяннее ADJ\n",
      "верхней ADJ\n",
      "Среди ADP\n",
      "сотрудников NOUN\n",
      "и CCONJ\n",
      "выпускников NOUN\n",
      "МФТИ PROPN\n",
      "нобелевских ADJ\n",
      "лауреатов NOUN\n",
      "ОГПУ PROPN\n",
      "направило VERB\n",
      "в ADP\n",
      "Лхасу PROPN\n",
      "свою DET\n",
      "новую ADJ\n",
      "экспедицию NOUN\n",
      "Джоулево NOUN\n",
      "тепло ADJ\n",
      "выделявшееся VERB\n",
      "в ADP\n",
      "образце NOUN\n",
      "не PART\n",
      "могло VERB\n",
      "приводить VERB\n",
      "к ADP\n",
      "перегреву NOUN\n",
      "Сяпала VERB\n",
      "Калуша PROPN\n",
      "с ADP\n",
      "калушатами NOUN\n",
      "по ADP\n",
      "напушке NOUN\n",
      "И CCONJ\n",
      "увазила VERB\n",
      "бутявку NOUN\n",
      "и CCONJ\n",
      "волит VERB\n",
      "Калушата PROPN\n",
      "Калушаточки NOUN\n",
      "Бутявка PROPN\n",
      "Калушата PROPN\n",
      "присяпали VERB\n",
      "и CCONJ\n",
      "бутявку NOUN\n",
      "стрямкали VERB\n",
      "И CCONJ\n",
      "подудонились VERB\n",
      "А CCONJ\n",
      "Калуша PROPN\n",
      "волит VERB\n",
      "Оее PROPN\n",
      "Бутявка NOUN\n",
      "некузявая ADJ\n",
      "Калушата PROPN\n",
      "бутявку NOUN\n",
      "вычучили VERB\n",
      "Бутявка NOUN\n",
      "вздребезнулась VERB\n",
      "сопритюкнулась VERB\n",
      "и CCONJ\n",
      "усяпала VERB\n",
      "с ADP\n",
      "напушки NOUN\n",
      "А CCONJ\n",
      "Калуша PROPN\n",
      "волит VERB\n",
      "Калушаточки PROPN\n",
      "бутявок NOUN\n",
      "не PART\n",
      "трямкают VERB\n",
      "бутявки NOUN\n",
      "дюбые ADJ\n",
      "и CCONJ\n",
      "зюмо VERB\n",
      "некузявые ADJ\n",
      "От ADP\n",
      "бутявок NOUN\n",
      "дудонятся VERB\n",
      "А CCONJ\n",
      "бутявка NOUN\n",
      "волит VERB\n",
      "за ADP\n",
      "напушкой NOUN\n",
      "Калушата PROPN\n",
      "подудонились VERB\n",
      "Зюмо VERB\n",
      "некузявые ADJ\n",
      "Пуськи NOUN\n",
      "бятые ADJ\n",
      "Варкалось VERB\n",
      "Хливкие ADJ\n",
      "шорьки NOUN\n",
      "Пырялись VERB\n",
      "по ADP\n",
      "наве NOUN\n",
      "И CCONJ\n",
      "хрюкотали VERB\n",
      "зелюки NOUN\n",
      "Как SCONJ\n",
      "мюмзики NOUN\n",
      "в ADP\n",
      "мове NOUN\n",
      "О ADP\n",
      "бойся VERB\n",
      "Бармаглота PROPN\n",
      "сын NOUN\n",
      "Он PRON\n",
      "так ADV\n",
      "свирлеп PROPN\n",
      "и CCONJ\n",
      "дик PROPN\n",
      "А CCONJ\n",
      "в ADP\n",
      "глyще NOUN\n",
      "рымит VERB\n",
      "исполин NOUN\n",
      "Злопастный VERB\n",
      "Брандашмыг PROPN\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "spacy_words = []\n",
    "spacy_tags = []\n",
    "nlp = spacy.load(\"ru_core_news_sm\")\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    if token.text.isalpha():\n",
    "        spacy_words.append(token.text)\n",
    "        spacy_tags.append(token.pos_)\n",
    "        print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403c8400",
   "metadata": {},
   "source": [
    "Чтобы все теги в разных POS тэгерах были одинаковые, создаем свой словарь, где приведем все к одному стандарту. Не будем различать AUX и VERB, CONJ и SCONJ, так как Mystem это не умеет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d2bdf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tag_translator = {\n",
    "    \"AUX\": \"VERB\",\n",
    "    \"PROPN\": \"NOUN\",\n",
    "    \"CCONJ\": \"CONJ\",\n",
    "    \"SCONJ\": \"CONJ\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1bc1d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(spacy_tags)):\n",
    "    if spacy_tags[i] in spacy_tag_translator.keys():\n",
    "        spacy_tags[i] = spacy_tag_translator[spacy_tags[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10e03499",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
    "!tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n",
    "!cp mystem /bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51583e0e",
   "metadata": {},
   "source": [
    "2. Используем второй тэггер Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85e1a64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f718f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
    "!tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n",
    "!cp mystem /root/.local/bin/mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "528cd408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing mystem to /Users/nastyapakhomova/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-macosx.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Перед PR\n",
      "нами SPRO\n",
      "была V\n",
      "огромная A\n",
      "пропасть S\n",
      "Грибов S\n",
      "здесь ADVPRO\n",
      "можно ADV\n",
      "набрать V\n",
      "пропасть S\n",
      "Тьфу INTJ\n",
      "ты SPRO\n",
      "пропасть S\n",
      "как CONJ\n",
      "надоел V\n",
      "В PR\n",
      "таком APRO\n",
      "месте S\n",
      "легко ADV\n",
      "пропасть S\n",
      "Антуан S\n",
      "ЛеКультр S\n",
      "сумел V\n",
      "поднять V\n",
      "точность S\n",
      "обработки S\n",
      "деталей S\n",
      "механизма S\n",
      "до PR\n",
      "невиданного A\n",
      "прежде ADV\n",
      "уровня S\n",
      "благодаря PR\n",
      "изобретению S\n",
      "миллионометра S\n",
      "прибора S\n",
      "для PR\n",
      "измерения S\n",
      "с PR\n",
      "точностью S\n",
      "до PR\n",
      "микрона S\n",
      "Частота S\n",
      "колебаний S\n",
      "баланса S\n",
      "определяется V\n",
      "числом S\n",
      "полуколебаний S\n",
      "балансового A\n",
      "колеса S\n",
      "в PR\n",
      "час S\n",
      "Москомэкспертиза S\n",
      "согласовала V\n",
      "проект S\n",
      "строительства S\n",
      "восьмидесятиэтажного A\n",
      "многофункционального A\n",
      "комплекса S\n",
      "Постоянно ADV\n",
      "стригя -\n",
      "волосы S\n",
      "мы SPRO\n",
      "заставляем V\n",
      "организм S\n",
      "все APRO\n",
      "время S\n",
      "вкладывать V\n",
      "огромные A\n",
      "ресурсы S\n",
      "в PR\n",
      "их APRO\n",
      "рост S\n",
      "Этим APRO\n",
      "скипетром S\n",
      "я SPRO\n",
      "побежу V\n",
      "даже CONJ\n",
      "лорда S\n",
      "демонов S\n",
      "За PR\n",
      "то SPRO\n",
      "нельзя ADV\n",
      "браться V\n",
      "а CONJ\n",
      "за PR\n",
      "это SPRO\n",
      "еще ADV\n",
      "нельзей S\n",
      "Я SPRO\n",
      "висю S\n",
      "под PR\n",
      "потолком S\n",
      "вместо PR\n",
      "лампы S\n",
      "Нижняя A\n",
      "полка S\n",
      "деревяннее A\n",
      "верхней A\n",
      "Среди PR\n",
      "сотрудников S\n",
      "и CONJ\n",
      "выпускников S\n",
      "МФТИ S\n",
      "нобелевских A\n",
      "лауреатов S\n",
      "ОГПУ S\n",
      "направило V\n",
      "в PR\n",
      "Лхасу S\n",
      "свою APRO\n",
      "новую A\n",
      "экспедицию S\n",
      "Джоулево S\n",
      "тепло ADV\n",
      "выделявшееся V\n",
      "в PR\n",
      "образце S\n",
      "не PART\n",
      "могло V\n",
      "приводить V\n",
      "к PR\n",
      "перегреву S\n",
      "Сяпала V\n",
      "Калуша S\n",
      "с PR\n",
      "калушатами S\n",
      "по PR\n",
      "напушке S\n",
      "И CONJ\n",
      "увазила S\n",
      "бутявку S\n",
      "и CONJ\n",
      "волит V\n",
      "Калушата S\n",
      "Калушаточки S\n",
      "Бутявка S\n",
      "Калушата S\n",
      "присяпали V\n",
      "и CONJ\n",
      "бутявку S\n",
      "стрямкали V\n",
      "И CONJ\n",
      "подудонились V\n",
      "А CONJ\n",
      "Калуша S\n",
      "волит V\n",
      "Оее -\n",
      "Бутявка S\n",
      "некузявая A\n",
      "Калушата S\n",
      "бутявку S\n",
      "вычучили V\n",
      "Бутявка S\n",
      "вздребезнулась S\n",
      "сопритюкнулась V\n",
      "и CONJ\n",
      "усяпала V\n",
      "с PR\n",
      "напушки S\n",
      "А CONJ\n",
      "Калуша S\n",
      "волит V\n",
      "Калушаточки S\n",
      "бутявок S\n",
      "не PART\n",
      "трямкают V\n",
      "бутявки S\n",
      "дюбые S\n",
      "и CONJ\n",
      "зюмо S\n",
      "некузявые A\n",
      "От PR\n",
      "бутявок S\n",
      "дудонятся V\n",
      "А CONJ\n",
      "бутявка S\n",
      "волит V\n",
      "за PR\n",
      "напушкой S\n",
      "Калушата S\n",
      "подудонились V\n",
      "Зюмо S\n",
      "некузявые A\n",
      "Пуськи S\n",
      "бятые S\n",
      "Варкалось V\n",
      "Хливкие A\n",
      "шорьки S\n",
      "Пырялись V\n",
      "по PR\n",
      "наве S\n",
      "И CONJ\n",
      "хрюкотали V\n",
      "зелюки S\n",
      "Как CONJ\n",
      "мюмзики S\n",
      "в PR\n",
      "мове S\n",
      "О PR\n",
      "бойся V\n",
      "Бармаглота S\n",
      "сын S\n",
      "Он SPRO\n",
      "так ADVPRO\n",
      "свирлеп A\n",
      "и CONJ\n",
      "дик A\n",
      "А CONJ\n",
      "в PR\n",
      "глyще ADV\n",
      "рымит V\n",
      "исполин S\n",
      "Злопастный A\n",
      "Брандашмыг ADV\n"
     ]
    }
   ],
   "source": [
    "m = Mystem()\n",
    "mystem_words = []\n",
    "mystem_tags = []\n",
    "nlp = m.analyze(text)\n",
    "for word in nlp:\n",
    "    if 'analysis' in word:\n",
    "        if len(word['analysis']) > 0:\n",
    "            gr = word['analysis'][0]['gr']\n",
    "        else:\n",
    "            gr = '-'\n",
    "        pos = gr.split('=')[0].split(',')[0]\n",
    "        mystem_words.append(word['text'])\n",
    "        mystem_tags.append(pos)\n",
    "        print(word['text'], pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b747e8",
   "metadata": {},
   "source": [
    "Объединяем ADVPRO (местоимения-наречия) и APRO (местоимения-прилагательные), так как spacy и stanza помечают их как DET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61433321",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_tag_translator = {\n",
    "    \"V\": \"VERB\",\n",
    "    \"S\": \"NOUN\",\n",
    "    \"A\": \"ADJ\",\n",
    "    \"PR\": \"ADP\",\n",
    "    \"SPRO\": \"PRON\",\n",
    "    \"ADVPRO\": \"DET\",\n",
    "    \"APRO\": \"DET\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "62270c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mystem_tags)):\n",
    "    if mystem_tags[i] in mystem_tag_translator.keys():\n",
    "        mystem_tags[i] = mystem_tag_translator[mystem_tags[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1faada7",
   "metadata": {},
   "source": [
    "3. Используем третий тэггер Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "636c3089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 13:07:20 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe64db554d1483e8d88f68a42b345fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 13:07:21 INFO: Loading these models for language: ru (Russian):\n",
      "================================\n",
      "| Processor | Package          |\n",
      "--------------------------------\n",
      "| tokenize  | syntagrus        |\n",
      "| pos       | syntagrus_charlm |\n",
      "================================\n",
      "\n",
      "2023-10-07 13:07:21 INFO: Using device: cpu\n",
      "2023-10-07 13:07:21 INFO: Loading: tokenize\n",
      "2023-10-07 13:07:21 INFO: Loading: pos\n",
      "2023-10-07 13:07:21 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Перед ADP\n",
      "нами PRON\n",
      "была AUX\n",
      "огромная ADJ\n",
      "пропасть NOUN\n",
      "Грибов NOUN\n",
      "здесь ADV\n",
      "можно ADV\n",
      "набрать VERB\n",
      "пропасть NOUN\n",
      "Тьфу VERB\n",
      "ты PRON\n",
      "пропасть NOUN\n",
      "как SCONJ\n",
      "надоел VERB\n",
      "В ADP\n",
      "таком DET\n",
      "месте NOUN\n",
      "легко ADJ\n",
      "пропасть NOUN\n",
      "Антуан PROPN\n",
      "ЛеКультр PROPN\n",
      "сумел VERB\n",
      "поднять VERB\n",
      "точность NOUN\n",
      "обработки NOUN\n",
      "деталей NOUN\n",
      "механизма NOUN\n",
      "до ADP\n",
      "невиданного VERB\n",
      "прежде ADP\n",
      "уровня NOUN\n",
      "благодаря ADP\n",
      "изобретению NOUN\n",
      "миллионометра NOUN\n",
      "прибора NOUN\n",
      "для ADP\n",
      "измерения NOUN\n",
      "с ADP\n",
      "точностью NOUN\n",
      "до ADP\n",
      "микрона NOUN\n",
      "Частота NOUN\n",
      "колебаний NOUN\n",
      "баланса NOUN\n",
      "определяется VERB\n",
      "числом NOUN\n",
      "полуколебаний NOUN\n",
      "балансового ADJ\n",
      "колеса NOUN\n",
      "в ADP\n",
      "час NOUN\n",
      "Москомэкспертиза NOUN\n",
      "согласовала VERB\n",
      "проект NOUN\n",
      "строительства NOUN\n",
      "восьмидесятиэтажного ADJ\n",
      "многофункционального ADJ\n",
      "комплекса NOUN\n",
      "Постоянно ADV\n",
      "стригя VERB\n",
      "волосы NOUN\n",
      "мы PRON\n",
      "заставляем VERB\n",
      "организм NOUN\n",
      "все DET\n",
      "время NOUN\n",
      "вкладывать VERB\n",
      "огромные ADJ\n",
      "ресурсы NOUN\n",
      "в ADP\n",
      "их DET\n",
      "рост NOUN\n",
      "Этим DET\n",
      "скипетром NOUN\n",
      "я PRON\n",
      "побежу VERB\n",
      "даже PART\n",
      "лорда NOUN\n",
      "демонов NOUN\n",
      "За ADP\n",
      "то PRON\n",
      "нельзя ADV\n",
      "браться VERB\n",
      "а CCONJ\n",
      "за ADP\n",
      "это PRON\n",
      "еще ADV\n",
      "нельзей ADJ\n",
      "Я PRON\n",
      "висю VERB\n",
      "под ADP\n",
      "потолком NOUN\n",
      "вместо ADP\n",
      "лампы NOUN\n",
      "Нижняя ADJ\n",
      "полка NOUN\n",
      "деревяннее ADJ\n",
      "верхней ADJ\n",
      "Среди ADP\n",
      "сотрудников NOUN\n",
      "и CCONJ\n",
      "выпускников NOUN\n",
      "МФТИ PROPN\n",
      "нобелевских ADJ\n",
      "лауреатов NOUN\n",
      "ОГПУ NOUN\n",
      "направило VERB\n",
      "в ADP\n",
      "Лхасу PROPN\n",
      "свою DET\n",
      "новую ADJ\n",
      "экспедицию NOUN\n",
      "Джоулево NOUN\n",
      "тепло ADJ\n",
      "выделявшееся VERB\n",
      "в ADP\n",
      "образце NOUN\n",
      "не PART\n",
      "могло VERB\n",
      "приводить VERB\n",
      "к ADP\n",
      "перегреву NOUN\n",
      "Сяпала VERB\n",
      "Калуша PROPN\n",
      "с ADP\n",
      "калушатами NOUN\n",
      "по ADP\n",
      "напушке NOUN\n",
      "И CCONJ\n",
      "увазила VERB\n",
      "бутявку NOUN\n",
      "и CCONJ\n",
      "волит VERB\n",
      "Калушата PROPN\n",
      "Калушаточки NOUN\n",
      "Бутявка NOUN\n",
      "Калушата NOUN\n",
      "присяпали VERB\n",
      "и CCONJ\n",
      "бутявку NOUN\n",
      "стрямкали VERB\n",
      "И CCONJ\n",
      "подудонились VERB\n",
      "А CCONJ\n",
      "Калуша PROPN\n",
      "волит VERB\n",
      "Оее INTJ\n",
      "Бутявка NOUN\n",
      "некузявая VERB\n",
      "Калушата NOUN\n",
      "бутявку NOUN\n",
      "вычучили VERB\n",
      "Бутявка NOUN\n",
      "вздребезнулась VERB\n",
      "сопритюкнулась VERB\n",
      "и CCONJ\n",
      "усяпала VERB\n",
      "с ADP\n",
      "напушки NOUN\n",
      "А CCONJ\n",
      "Калуша PROPN\n",
      "волит VERB\n",
      "Калушаточки NOUN\n",
      "бутявок NOUN\n",
      "не PART\n",
      "трямкают VERB\n",
      "бутявки NOUN\n",
      "дюбые ADJ\n",
      "и CCONJ\n",
      "зюмо NOUN\n",
      "некузявые ADJ\n",
      "От ADP\n",
      "бутявок NOUN\n",
      "дудонятся VERB\n",
      "А CCONJ\n",
      "бутявка NOUN\n",
      "волит VERB\n",
      "за ADP\n",
      "напушкой NOUN\n",
      "Калушата PROPN\n",
      "подудонились VERB\n",
      "Зюмо NOUN\n",
      "некузявые ADJ\n",
      "Пуськи NOUN\n",
      "бятые ADJ\n",
      "Варкалось NOUN\n",
      "Хливкие ADJ\n",
      "шорьки NOUN\n",
      "Пырялись VERB\n",
      "по ADP\n",
      "наве NOUN\n",
      "И CCONJ\n",
      "хрюкотали VERB\n",
      "зелюки NOUN\n",
      "Как ADV\n",
      "мюмзики NOUN\n",
      "в ADP\n",
      "мове NOUN\n",
      "О INTJ\n",
      "бойся VERB\n",
      "Бармаглота PROPN\n",
      "сын NOUN\n",
      "Он PRON\n",
      "так ADV\n",
      "свирлеп VERB\n",
      "и CCONJ\n",
      "дик NOUN\n",
      "А CCONJ\n",
      "в ADP\n",
      "глyще NOUN\n",
      "рымит VERB\n",
      "исполин NOUN\n",
      "Злопастный ADJ\n",
      "Брандашмыг PROPN\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "stanza_words = []\n",
    "stanza_tags = []\n",
    "\n",
    "nlp = stanza.Pipeline(lang='ru', processors='tokenize,pos')\n",
    "doc = nlp(text)\n",
    "\n",
    "for sent in doc.sentences:\n",
    "    for word in sent.words:\n",
    "        if word.upos != \"PUNCT\":\n",
    "            if word.upos != \"NUM\": #потому что так он считает 10 за слово и у меня не сходится число tags для вычисления accuracy\n",
    "                stanza_words.append(word.text)\n",
    "                stanza_tags.append(word.upos)\n",
    "                print(word.text, word.upos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b205209",
   "metadata": {},
   "source": [
    "У stanza тот же тегсет, что и у spacy, функцию можно не менять."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83e0c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tag_translator = {\n",
    "    \"AUX\": \"VERB\",\n",
    "    \"PROPN\": \"NOUN\",\n",
    "    \"CCONJ\": \"CONJ\",\n",
    "    \"SCONJ\": \"CONJ\"\n",
    "}\n",
    "\n",
    "for i in range(len(stanza_tags)):\n",
    "    if stanza_tags[i] in spacy_tag_translator.keys():\n",
    "        stanza_tags[i] = spacy_tag_translator[stanza_tags[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6268fa",
   "metadata": {},
   "source": [
    "Чтобы проверить accuracy, нужно убедиться, что сллва сходятся во всех трех тэгеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "85937f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words == spacy_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cecdec4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_words == mystem_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a0b4cf09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_words == stanza_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c7b24216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4058de55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "spacy: 0.9255813953488372\n",
      "mystem: 0.8976744186046511\n",
      "stanza: 0.8\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy\")\n",
    "print(\"spacy:\", accuracy_score(tags, spacy_tags))\n",
    "print(\"mystem:\", accuracy_score(tags, mystem_tags))\n",
    "print(\"stanza:\", accuracy_score(tags, stanza_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eac5037",
   "metadata": {},
   "source": [
    "В результате проверки, получилось, что spacy - это лучший тэггер, который имеет лучшую точность."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783d8b80",
   "metadata": {},
   "source": [
    "4. Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "97af1882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: selenium in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.12.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: trio~=0.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from selenium) (0.10.4)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trio~=0.17->selenium) (22.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.1.3)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cc7da316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cb96950a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: chromedriver-autoinstaller in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.6.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~atplotlib (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install chromedriver-autoinstaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ac42944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "import ssl\n",
    "import json\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b7c02306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "90eed291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHROME >= 115.0.5763.0, using mac-arm64 as architecture identifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/chromedriver_autoinstaller/117/chromedriver'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import chromedriver_autoinstaller\n",
    "import sys\n",
    "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless') # ensure GUI is off\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# set path to chromedriver as per your configuration\n",
    "chromedriver_autoinstaller.install()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfb03ec",
   "metadata": {},
   "source": [
    "Берем код из дз1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c20ad8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(url, num):\n",
    "\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "\n",
    "    last_position = driver.execute_script('return window.pageYOffset;')\n",
    "    reviews = []\n",
    "    review_ids = set()\n",
    "\n",
    "    while True:\n",
    "      cards = driver.find_elements(By.CLASS_NAME, 'apphub_Card')\n",
    "      if(len(cards) >= num):\n",
    "          break\n",
    "      last_position = driver.execute_script('return window.pageYOffset;')\n",
    "      driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "      sleep(0.5)\n",
    "      curr_position = driver.execute_script('return window.pageYOffset;')\n",
    "      if(last_position == curr_position):\n",
    "          continue\n",
    "\n",
    "    reviews = []\n",
    "    for card in cards[:num]:\n",
    "        date_posted = card.find_element(By.XPATH, './/div[@class=\"apphub_CardTextContent\"]/div').text\n",
    "        review_content = card.find_element(By.XPATH, './/div[@class=\"apphub_CardTextContent\"]').text.replace(date_posted, '').strip()\n",
    "        reviews.append(review_content)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7c3758e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews = get_reviews('https://steamcommunity.com/app/203140/positivereviews/?filterLanguage=english&p=1&browsefilter=toprated.html', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0bb4fdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_reviews = get_reviews('https://steamcommunity.com/app/203140/negativereviews/?filterLanguage=english&p=1&browsefilter=toprated.html', 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5c6df92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Positive Aspects\\n-Pretty good graphics and unique artstyle.\\n-Simplified gameplay, both stealth and movement.\\n-Action packed Story that stays somewhat loyal to the franchise\\n-Very good Performance\\n\\nNegative Aspects\\n-Not a traditional Hitman game\\n-Game doesn't require as much skill when comapred to previous entries\\n\\nHitman Absolution was released in 2012 by Io Interactive and was the next game after Hitman Blood Money.\\nYour mission is to save Victoria and assasinate your long time co worker Diana Burnwood because she apparently gave information to other people about the agency. While you try to kill her she explains you everything and how corrupted the Agency actually is.\\n\\nSo as an Elite Assasin you decide to fight against the agency in order to reveal what type of shady organisation the Agency actually is, at the same time you try to kill Blake Dexter which is the man that tried to kill you and sell Victoria to the Agency.\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_reviews[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "39415ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Contracts Servers are down ( i dont care if its Io-Interactive or square enix fault, lack of interest or whatever )\\nAbout 50 % of the game is useless now. Contracts Mode is still advertised as a Feature of the Game, so are the unachievable Achievements'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_reviews[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64b2929",
   "metadata": {},
   "source": [
    "Делим данные на тестовые и обучающие"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4712d243",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = positive_reviews[0:10] + negative_reviews[0:10]\n",
    "positive_reviews = positive_reviews[-100:]\n",
    "negative_reviews = negative_reviews[-100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d7685d",
   "metadata": {},
   "source": [
    "Лемматизируем и токенизируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8c1ae5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "my_tokens = []\n",
    "def lemmatize(text):\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        if word.pos_ != \"PUNCT\" and word.pos_ !=  \"NUM\":\n",
    "            my_tokens.append(word.lemma_.lower())\n",
    "    return my_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "bfa75045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['папа',\n",
       " 'сказать',\n",
       " 'что',\n",
       " 'если',\n",
       " 'на',\n",
       " 'этот',\n",
       " 'обзор',\n",
       " 'наберётся',\n",
       " 'лайк',\n",
       " 'и',\n",
       " 'награда',\n",
       " 'то',\n",
       " 'он',\n",
       " 'побрить',\n",
       " 'меня',\n",
       " 'налысый',\n",
       " 'и',\n",
       " 'набьёт',\n",
       " 'штрих',\n",
       " '-',\n",
       " 'код',\n",
       " 'от',\n",
       " 'холодильник',\n",
       " 'на',\n",
       " 'затылок']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(\"Папа сказал что если на этом обзоре наберётся 4 лайка и 7 наград,то он побреет меня налысо и набьёт штрих-код от холодильника на затылок\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450ad4af",
   "metadata": {},
   "source": [
    "Делаем подсчет вхождений каждого слова в положительных и отрицательных отзывах, создаем два словаря частотности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "053d5655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def collect_freqlist(reviews):\n",
    "    freqlist = Counter()\n",
    "    for review in reviews:\n",
    "        for token in lemmatize(review):\n",
    "            freqlist[token] += 1\n",
    "    return freqlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e6c431",
   "metadata": {},
   "source": [
    "Выкидываем слова, встречающиеся 1-2 раза, и создаем 2 множества - в одном будут слова, которые встречаются только в положительных отзывах, а в другом - встречающиеся только в отрицательных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "2f40be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_freqlists(positive_reviews, negative_reviews):\n",
    "    positive_freqlist = collect_freqlist(positive_reviews)\n",
    "    negative_freqlist = collect_freqlist(negative_reviews)\n",
    "    positive_freqlist = set(k for k, v in positive_freqlist.items() if v > 2)\n",
    "    negative_freqlist = set(k for k, v in negative_freqlist.items() if v > 2)\n",
    "    positive_freqlist_unique = positive_freqlist - negative_freqlist\n",
    "    negative_freqlist_unique = negative_freqlist - positive_freqlist\n",
    "    return positive_freqlist_unique, negative_freqlist_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "5cb2e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_freqlist_unique, negative_freqlist_unique = prepare_freqlists(positive_reviews, negative_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "8f9adfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_sentiment_analysis(positive_freqlist, negative_freqlist, test):\n",
    "    prediction = []\n",
    "    for review in test:\n",
    "        positive_count = 0\n",
    "        negative_count = 0\n",
    "        for token in lemmatize(review):\n",
    "            if token in positive_freqlist:\n",
    "                positive_count += 1\n",
    "            elif token in negative_freqlist:\n",
    "                negative_count += 1\n",
    "        if positive_count > negative_count:\n",
    "            prediction.append(1)\n",
    "        else:\n",
    "            prediction.append(0)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b18197a",
   "metadata": {},
   "source": [
    "Правильные ответы (положительный отзыв - 1, отрицательный отзыв - 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "6f943108",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_answers = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "1462a85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = simple_sentiment_analysis(positive_freqlist_unique, negative_freqlist_unique, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77097d2",
   "metadata": {},
   "source": [
    "Считаем точность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "940f9340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %.4f' % accuracy_score(prediction, correct_answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e689c78",
   "metadata": {},
   "source": [
    "Шаблоны: это сочетания слов со значением усиления или отрицания.\n",
    "1: не + VERB (не получилось, не нравится, не люблю) - будет давать балл к отрицательному, а не положительному\n",
    "2: очень + ADJ (очень нравится, очень напрягло) - будет давать дополнительный балл к прилагательному\n",
    "3: нет + NOUN (нет сюжета, нет интереса) - балл к отрицательному\n",
    "\n",
    "Биграммы будем брать с весом 2 вместо 1 (иначе \"не нравится\" + \"нравится\" взаимоисключатся вместо того, чтобы прибавить балл к отрицательному)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "a36fd06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    parts_of_speech = []\n",
    "    my_tokens = []\n",
    "    sentences = re.split('!|\\n|\\.', text)\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        if word.pos_ != \"PUNCT\" and word.pos_ !=  \"NUM\":\n",
    "            my_tokens.append(word.lemma_.lower())\n",
    "            my_tokens.append(parsed[2].lower())\n",
    "            parts_of_speech.append(parsed[3])\n",
    "    bigrams = []\n",
    "    for i in range(len(my_tokens) - 1):\n",
    "        if (my_tokens[i] == 'не' and parts_of_speech[i+1] == 'VERB') or \\\n",
    "            (my_tokens[i] == 'очень' and parts_of_speech[i+1] == 'ADJ') or \\\n",
    "            (my_tokens[i] == 'нет' and parts_of_speech[i+1] == 'NOUN'):\n",
    "            for j in range(2):\n",
    "                bigrams.append(my_tokens[i] + ' ' + my_tokens[i+1])\n",
    "\n",
    "    return my_tokens + bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "30cc6051",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[275], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m positive_freqlist_unique, negative_freqlist_unique \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_freqlists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositive_reviews\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative_reviews\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[256], line 2\u001b[0m, in \u001b[0;36mprepare_freqlists\u001b[0;34m(positive_reviews, negative_reviews)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_freqlists\u001b[39m(positive_reviews, negative_reviews):\n\u001b[0;32m----> 2\u001b[0m     positive_freqlist \u001b[38;5;241m=\u001b[39m \u001b[43mcollect_freqlist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositive_reviews\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     negative_freqlist \u001b[38;5;241m=\u001b[39m collect_freqlist(negative_reviews)\n\u001b[1;32m      4\u001b[0m     positive_freqlist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m positive_freqlist\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[255], line 6\u001b[0m, in \u001b[0;36mcollect_freqlist\u001b[0;34m(reviews)\u001b[0m\n\u001b[1;32m      4\u001b[0m freqlist \u001b[38;5;241m=\u001b[39m Counter()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m review \u001b[38;5;129;01min\u001b[39;00m reviews:\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreview\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      7\u001b[0m         freqlist[token] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m freqlist\n",
      "Cell \u001b[0;32mIn[274], line 9\u001b[0m, in \u001b[0;36mlemmatize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39mpos_ \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPUNCT\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m word\u001b[38;5;241m.\u001b[39mpos_ \u001b[38;5;241m!=\u001b[39m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNUM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      8\u001b[0m         my_tokens\u001b[38;5;241m.\u001b[39mappend(word\u001b[38;5;241m.\u001b[39mlemma_\u001b[38;5;241m.\u001b[39mlower())\n\u001b[0;32m----> 9\u001b[0m         my_tokens\u001b[38;5;241m.\u001b[39mappend(\u001b[43mparsed\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mlower())\n\u001b[1;32m     10\u001b[0m         parts_of_speech\u001b[38;5;241m.\u001b[39mappend(parsed[\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m     11\u001b[0m bigrams \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "positive_freqlist_unique, negative_freqlist_unique = prepare_freqlists(positive_reviews, negative_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc59818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
